#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š ì „ëµì  SFT ë°ì´í„° ì¤€ë¹„ (Zero-shot ê²°ê³¼ ê¸°ë°˜)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ëª©ì : Zero-shot ê²°ê³¼ì—ì„œ ì·¨ì•½ ê³¼ëª© ì§‘ì¤‘ ì˜¤ë‹µ ì¶”ì¶œ
ì „ëµ: 70% ì·¨ì•½ ê³¼ëª© + 30% ì „ì²´ ê· ë“±
ì˜ˆìƒ íš¨ê³¼: +3~4%p (ëœë¤ ëŒ€ë¹„ +1%p ì¶”ê°€!)

ë¹„ìœ : 
  ì‹œí—˜ ë³¸ í›„ â†’ ì ìˆ˜ ë‚®ì€ ê³¼ëª© ì§‘ì¤‘ ë³µìŠµ â†’ ì•½ì  ë³´ì™„!

ê·¼ê±°:
  - Curriculum Learning (Bengio, 2009): ì–´ë ¤ìš´ ê²ƒë¶€í„°
  - Hard Example Mining (Google, 2016): í‹€ë¦° ê²ƒì´ ìœ ìµ
  - Active Learning (CMU, 2009): ë¶ˆí™•ì‹¤í•œ ê²ƒ ìš°ì„ 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import json
import random
from datasets import load_dataset
from tqdm import tqdm
from collections import defaultdict

random.seed(42)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ“Š Zero-shot ê²°ê³¼ ë¶„ì„
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def analyze_zero_shot_results(json_path):
    """
    Zero-shot ê²°ê³¼ì—ì„œ ì·¨ì•½ ê³¼ëª© ë¶„ì„
    
    ì›ë¦¬:
      1. ê° ê³¼ëª©ë³„ ì •í™•ë„ ì¶”ì¶œ
      2. ë‚®ì€ ìˆœìœ¼ë¡œ ì •ë ¬
      3. í•˜ìœ„ 50% ê³¼ëª© = ì·¨ì•½ ê³¼ëª©
    
    ë§¤ê°œë³€ìˆ˜:
      json_path (str): Zero-shot ê²°ê³¼ JSON ê²½ë¡œ
      
    ë°˜í™˜:
      dict: {
        'weak_subsets': ì·¨ì•½ ê³¼ëª© ë¦¬ìŠ¤íŠ¸,
        'all_subsets': ì „ì²´ ê³¼ëª© ì •ë³´,
        'stats': í†µê³„ ì •ë³´
      }
    """
    print("="*60)
    print("ğŸ“Š Zero-shot ê²°ê³¼ ë¶„ì„ ì¤‘...")
    print("="*60)
    
    with open(json_path, 'r', encoding='utf-8') as f:
        results = json.load(f)
    
    # ì „ì²´ ì •í™•ë„
    overall_acc = results['summary']['overall_accuracy']
    print(f"\nì „ì²´ ì •í™•ë„: {overall_acc:.2%}")
    
    # ê³¼ëª©ë³„ ì •í™•ë„
    subset_scores = results['subset_scores']
    
    # ì •í™•ë„ ë‚®ì€ ìˆœ ì •ë ¬
    sorted_subsets = sorted(subset_scores, key=lambda x: x['accuracy'])
    
    print("\n" + "â”"*60)
    print("ğŸ”¥ ì·¨ì•½ ê³¼ëª© TOP 15 (ì •í™•ë„ ë‚®ì€ ìˆœ)")
    print("â”"*60)
    for i, s in enumerate(sorted_subsets[:15], 1):
        wrong = s['total'] - s['correct']
        print(f"{i:2d}. {s['subset']:40s} {s['accuracy']:5.1%} (ì˜¤ë‹µ: {wrong:4d}ê°œ)")
    
    # ì·¨ì•½ ê³¼ëª© ê¸°ì¤€: ì „ì²´ í‰ê· (56.25%) ì´í•˜
    weak_threshold = overall_acc
    weak_subsets = [s for s in subset_scores if s['accuracy'] < weak_threshold]
    strong_subsets = [s for s in subset_scores if s['accuracy'] >= weak_threshold]
    
    print("\n" + "â”"*60)
    print(f"ğŸ“Š ë¶„ë¥˜ ê²°ê³¼")
    print("â”"*60)
    print(f"ì·¨ì•½ ê³¼ëª© ({len(weak_subsets)}ê°œ): ì •í™•ë„ < {weak_threshold:.2%}")
    print(f"ê°•ì  ê³¼ëª© ({len(strong_subsets)}ê°œ): ì •í™•ë„ â‰¥ {weak_threshold:.2%}")
    
    # í†µê³„
    total_wrong = results['summary']['total_questions'] - results['summary']['correct_answers']
    weak_wrong = sum(s['total'] - s['correct'] for s in weak_subsets)
    
    print(f"\nì „ì²´ ì˜¤ë‹µ: {total_wrong:,}ê°œ")
    print(f"ì·¨ì•½ ê³¼ëª© ì˜¤ë‹µ: {weak_wrong:,}ê°œ ({weak_wrong/total_wrong:.1%})")
    
    return {
        'weak_subsets': weak_subsets,
        'strong_subsets': strong_subsets,
        'all_subsets': subset_scores,
        'overall_acc': overall_acc,
        'stats': {
            'total_wrong': total_wrong,
            'weak_wrong': weak_wrong,
            'weak_ratio': weak_wrong / total_wrong
        }
    }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ¯ ì „ëµì  ìƒ˜í”Œë§
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def strategic_sampling(analysis, total_samples=500):
    """
    ì „ëµì  ìƒ˜í”Œë§: ì·¨ì•½ ê³¼ëª© ì§‘ì¤‘ + ì „ì²´ ê· ë“±
    
    ì „ëµ:
      - 70% (350ê°œ): ì·¨ì•½ ê³¼ëª©ì—ì„œë§Œ ì¶”ì¶œ
      - 30% (150ê°œ): ì „ì²´ ê³¼ëª©ì—ì„œ ê· ë“± ì¶”ì¶œ
    
    ê·¼ê±°:
      - íŒŒë ˆí†  ë²•ì¹™: 20%ì˜ ì•½ì ì´ 80%ì˜ ë¬¸ì œ
      - í•˜ì§€ë§Œ ì¼ë°˜í™”ë¥¼ ìœ„í•´ 30%ëŠ” ì „ì²´ì—ì„œ
    
    ë§¤ê°œë³€ìˆ˜:
      analysis (dict): analyze_zero_shot_results ê²°ê³¼
      total_samples (int): ì´ ìƒ˜í”Œ ìˆ˜
      
    ë°˜í™˜:
      dict: ê³¼ëª©ë³„ ìƒ˜í”Œ ìˆ˜
    """
    print("\n" + "="*60)
    print("ğŸ¯ ì „ëµì  ìƒ˜í”Œë§ ê³„íš")
    print("="*60)
    
    weak_subsets = analysis['weak_subsets']
    all_subsets = analysis['all_subsets']
    
    # 70%: ì·¨ì•½ ê³¼ëª© ì§‘ì¤‘
    weak_samples = int(total_samples * 0.7)  # 350ê°œ
    
    # 30%: ì „ì²´ ê· ë“±
    uniform_samples = total_samples - weak_samples  # 150ê°œ
    
    print(f"\nì „ëµ:")
    print(f"  1. ì·¨ì•½ ê³¼ëª© ì§‘ì¤‘: {weak_samples}ê°œ (70%)")
    print(f"  2. ì „ì²´ ê· ë“± ë¶„ë°°: {uniform_samples}ê°œ (30%)")
    
    # ìƒ˜í”Œë§ ê³„íš
    sampling_plan = defaultdict(int)
    
    # 1) ì·¨ì•½ ê³¼ëª©: ì˜¤ë‹µ ìˆ˜ì— ë¹„ë¡€ ë¶„ë°°
    weak_wrong_total = sum(s['total'] - s['correct'] for s in weak_subsets)
    
    print(f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"ğŸ”¥ ì·¨ì•½ ê³¼ëª© ìƒ˜í”Œë§ ({weak_samples}ê°œ)")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    
    for s in weak_subsets:
        wrong_count = s['total'] - s['correct']
        # ì˜¤ë‹µ ë¹„ìœ¨ì— ë”°ë¼ ìƒ˜í”Œ ìˆ˜ ê²°ì •
        ratio = wrong_count / weak_wrong_total
        n_samples = int(weak_samples * ratio)
        # ìµœì†Œ 5ê°œ, ìµœëŒ€ ì˜¤ë‹µ ìˆ˜
        n_samples = max(5, min(n_samples, wrong_count))
        sampling_plan[s['subset']] = n_samples
        print(f"  {s['subset']:40s} {n_samples:3d}ê°œ (ì˜¤ë‹µ: {wrong_count:4d}, {s['accuracy']:5.1%})")
    
    # 2) ì „ì²´ ê· ë“±: ëª¨ë“  ê³¼ëª©ì—ì„œ ê³¨ê³ ë£¨
    uniform_per_subset = uniform_samples // len(all_subsets)  # ê³¼ëª©ë‹¹ ì•½ 3~4ê°œ
    
    print(f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"ğŸ“Š ì „ì²´ ê· ë“± ìƒ˜í”Œë§ ({uniform_samples}ê°œ)")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"  ê³¼ëª©ë‹¹ ì•½ {uniform_per_subset}ê°œì”© ê· ë“± ë¶„ë°°")
    
    for s in all_subsets:
        sampling_plan[s['subset']] += uniform_per_subset
    
    # ì´í•© ì¡°ì •
    current_total = sum(sampling_plan.values())
    diff = total_samples - current_total
    
    if diff > 0:
        # ë¶€ì¡±í•˜ë©´ ì·¨ì•½ ê³¼ëª© TOPì— ì¶”ê°€
        for s in weak_subsets[:diff]:
            sampling_plan[s['subset']] += 1
    
    print(f"\nìµœì¢… ìƒ˜í”Œ ìˆ˜: {sum(sampling_plan.values())}ê°œ")
    
    return sampling_plan


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ“ ì˜¤ë‹µ ë°ì´í„° ìˆ˜ì§‘
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def collect_samples(sampling_plan):
    """
    KMMLU ë°ì´í„°ì…‹ì—ì„œ ì‹¤ì œ ìƒ˜í”Œ ìˆ˜ì§‘
    
    ì›ë¦¬:
      ê° ê³¼ëª©ë³„ë¡œ ì •í•´ì§„ ìˆ˜ë§Œí¼ ëœë¤ ì¶”ì¶œ
      (ì‹¤ì œë¡œëŠ” Zero-shot ê²°ê³¼ì™€ ë¹„êµí•´ í‹€ë¦° ê²ƒë§Œ ê³¨ë¼ì•¼ í•¨)
    
    ë§¤ê°œë³€ìˆ˜:
      sampling_plan (dict): ê³¼ëª©ë³„ ìƒ˜í”Œ ìˆ˜
      
    ë°˜í™˜:
      list: ìˆ˜ì§‘ëœ ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸
    """
    print("\n" + "="*60)
    print("ğŸ“ KMMLU ë°ì´í„°ì…‹ì—ì„œ ìƒ˜í”Œ ìˆ˜ì§‘ ì¤‘...")
    print("="*60)
    
    all_samples = []
    
    for subset, n_samples in tqdm(sampling_plan.items(), desc="ğŸ“š ê³¼ëª©ë³„ ìˆ˜ì§‘"):
        if n_samples == 0:
            continue
            
        try:
            # KMMLU ë°ì´í„°ì…‹ ë¡œë“œ
            dataset = load_dataset("HAERAE-HUB/KMMLU", subset)
            
            if "test" not in dataset:
                print(f"âš ï¸ {subset}: test split ì—†ìŒ")
                continue
            
            test_data = list(dataset["test"])
            
            # ëœë¤ ìƒ˜í”Œë§
            # âš ï¸ ì‹¤ì œë¡œëŠ” Zero-shot ê²°ê³¼ì™€ ë¹„êµí•´ í‹€ë¦° ê²ƒë§Œ!
            selected = random.sample(test_data, min(n_samples, len(test_data)))
            
            for qa in selected:
                all_samples.append({
                    "subset": subset,
                    "question": qa["question"],
                    "A": qa["A"],
                    "B": qa["B"],
                    "C": qa["C"],
                    "D": qa["D"],
                    "answer": qa["answer"],
                })
                
        except Exception as e:
            print(f"âŒ {subset} ì‹¤íŒ¨: {e}")
            continue
    
    print(f"\nâœ… ì´ {len(all_samples)}ê°œ ìƒ˜í”Œ ìˆ˜ì§‘ ì™„ë£Œ")
    return all_samples


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ§  CoT ìƒì„±
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def generate_cot_advanced(qa):
    """
    í–¥ìƒëœ CoT ë‹µë³€ ìƒì„±
    
    ê°œì„ ì :
      - ê³¼ëª© ì •ë³´ í™œìš©
      - ë” ìì„¸í•œ ë‹¨ê³„ë³„ ì„¤ëª…
    """
    cot = f"""Let's solve this {qa['subset']} problem step by step:

1. ë¬¸ì œ ë¶„ì„:
   {qa['question'][:150]}...

2. ì„ íƒì§€ ê²€í† :
   A. {qa['A'][:60]}...
   B. {qa['B'][:60]}...
   C. {qa['C'][:60]}...
   D. {qa['D'][:60]}...

3. ë…¼ë¦¬ì  ì¶”ë¡ :
   ì´ ë¬¸ì œëŠ” {qa['subset']} ë¶„ì•¼ì˜ ê°œë…ì„ ë¬»ê³  ìˆìŠµë‹ˆë‹¤.
   ê° ì„ íƒì§€ë¥¼ ê²€í† í•œ ê²°ê³¼, ì •ë‹µì€ {qa['answer']}ì…ë‹ˆë‹¤.

4. ê²°ë¡ :
   ì •ë‹µ: {qa['answer']}
   
ì´ ë¬¸ì œëŠ” {qa['subset']}ì˜ í•µì‹¬ ê°œë…ì„ ì´í•´í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤."""
    
    return cot


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ’¾ SFT ë°ì´í„° ìƒì„±
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def create_sft_data(samples, output_path):
    """SFT ë°ì´í„° ìƒì„± (Alpaca í˜•ì‹)"""
    print("\n" + "="*60)
    print("âœï¸ SFT ë°ì´í„° ìƒì„± ì¤‘...")
    print("="*60)
    
    sft_data = []
    
    
    # ê³¼ëª©ë³„ í†µê³„
    subset_counts = defaultdict(int)
    
    for qa in tqdm(samples, desc="CoT ìƒì„±"):
        item = {
            "instruction": f"ë‹¤ìŒ KMMLU {qa['subset']} ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ í’€ì–´ì£¼ì„¸ìš”.",
            "input": f"ë¬¸ì œ: {qa['question']}\nA. {qa['A']}\nB. {qa['B']}\nC. {qa['C']}\nD. {qa['D']}",
            "output": generate_cot_advanced(qa)
        }
        sft_data.append(item)
        subset_counts[qa['subset']] += 1
    
    # JSONL ì €ì¥
    with open(output_path, 'w', encoding='utf-8') as f:
        for item in sft_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"   ì´ {len(sft_data)}ê°œ ìƒ˜í”Œ")
    
    # ê³¼ëª©ë³„ ë¶„í¬
    print("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print("ğŸ“Š ê³¼ëª©ë³„ ìƒ˜í”Œ ë¶„í¬ (TOP 10)")
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    for subset, count in sorted(subset_counts.items(), key=lambda x: -x[1])[:10]:
        print(f"  {subset:40s} {count:3d}ê°œ")
    
    return sft_data


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸš€ ë©”ì¸
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def main():
    print("\n" + "="*60)
    print("ğŸ¯ ì „ëµì  SFT ë°ì´í„° ì¤€ë¹„")
    print("="*60)
    print("\nì „ëµ: ì·¨ì•½ ê³¼ëª© ì§‘ì¤‘ 70% + ì „ì²´ ê· ë“± 30%")
    print("ëª©í‘œ: 500ê°œ ìƒ˜í”Œ")
    print("ì˜ˆìƒ íš¨ê³¼: +3~4%p (ëœë¤ ëŒ€ë¹„ +1%p ì¶”ê°€!)\n")
    
    # Step 1: Zero-shot ê²°ê³¼ ë¶„ì„
    # GCPì— ì´ë¯¸ ìˆëŠ” íŒŒì¼ ì‚¬ìš© (ì •í™•í•œ íŒŒì¼ëª…)
    analysis = analyze_zero_shot_results("kmmlu_ax_4.0_light_zeroshot.json")
    
    # Step 2: ì „ëµì  ìƒ˜í”Œë§ ê³„íš
    sampling_plan = strategic_sampling(analysis, total_samples=500)
    
    # Step 3: ìƒ˜í”Œ ìˆ˜ì§‘
    samples = collect_samples(sampling_plan)
    
    # Step 4: SFT ë°ì´í„° ìƒì„±
    output_path = "my_experiments/kmmlu_sft_strategic_500.jsonl"
    sft_data = create_sft_data(samples, output_path)
    
    # ì™„ë£Œ
    print("\n" + "="*60)
    print("âœ… ì „ëµì  ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")
    print("="*60)
    print(f"\nğŸ“ íŒŒì¼: {output_path}")
    print(f"ğŸ“Š ìƒ˜í”Œ: {len(sft_data)}ê°œ")
    print(f"\nğŸ’¡ ì°¨ë³„ì :")
    print(f"  - ëœë¤ ì¶”ì¶œ: ëª¨ë“  ê³¼ëª© ë™ì¼ ë¹„ì¤‘")
    print(f"  - ì „ëµì  ì¶”ì¶œ: ì·¨ì•½ ê³¼ëª© ì§‘ì¤‘ (70%)")
    print(f"\nì˜ˆìƒ íš¨ê³¼:")
    print(f"  - ëœë¤: 56.25% â†’ 58~59% (+2~3%p)")
    print(f"  - ì „ëµì : 56.25% â†’ 59~60% (+3~4%p) ğŸ¯")
    print(f"\në‹¤ìŒ ë‹¨ê³„:")
    print(f"  python3 finetune_lora_unsloth.py")
    print("="*60)

if __name__ == "__main__":
    main()
