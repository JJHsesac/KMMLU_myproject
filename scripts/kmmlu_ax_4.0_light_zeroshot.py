#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
KMMLU A.X-4.0-Light Zero-shot í‰ê°€ê¸°
====================================
íŒ€ ê³¼ì œìš© - ê°„ë‹¨í•˜ê³  í™•ì‹¤í•œ ë²„ì „

LangSmith ì—°ê²° (ì„ íƒ):
export LANGCHAIN_API_KEY="ls-..."  # ìˆìœ¼ë©´ ìë™ ì—°ê²°
"""

import torch
import pandas as pd
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
import re
import random
import argparse
from tqdm import tqdm
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from datetime import datetime
import json
import warnings
import os

warnings.filterwarnings('ignore')

# LangSmith ìë™ ê°ì§€
LANGSMITH_ENABLED = False
if os.getenv("LANGCHAIN_API_KEY"):
    try:
        from langsmith import Client
        os.environ["LANGCHAIN_TRACING_V2"] = "true"
        if not os.getenv("LANGCHAIN_PROJECT"):
            os.environ["LANGCHAIN_PROJECT"] = "kmmlu-experiments"
        LANGSMITH_ENABLED = True
        print("âœ… LangSmith í™œì„±í™”ë¨")
    except ImportError:
        print("âš ï¸ langsmith ë¯¸ì„¤ì¹˜ (pip install langsmith)")
else:
    print("â„¹ï¸ LangSmith ë¹„í™œì„±í™” (LANGCHAIN_API_KEY ì—†ìŒ)")


class KMMLUEvaluator:
    """A.X-4.0-Light Zero-shot í‰ê°€ê¸°"""
    
    def __init__(
        self,
        model_id: str = "skt/A.X-4.0-Light",
        batch_size: int = 2,
        seed: int = 42,
        output_prefix: str = "kmmlu_ax_zeroshot",
    ):
        self.model_id = model_id
        self.batch_size = batch_size
        self.seed = seed
        self.output_prefix = output_prefix
        self.langsmith = LANGSMITH_ENABLED
        
        # Random seed
        random.seed(seed)
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)
        
        self.tokenizer, self.model = self._load_model()
        self.subsets = self._get_subsets()
        self.categories = self._get_categories()
        
        self.answer_map = {
            "A": 0, "B": 1, "C": 2, "D": 3,
            "1": 0, "2": 1, "3": 2, "4": 3,
        }
    
    def _load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        print(f"\n{'='*60}")
        print(f"ğŸ¤– ëª¨ë¸: {self.model_id}")
        print(f"âš¡ Zero-shot (num_shots=0)")
        print(f"ğŸ² Seed: {self.seed}")
        print(f"{'='*60}\n")
        
        # 4bit ì–‘ìí™”
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_use_double_quant=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.bfloat16,
        )
        
        tokenizer = AutoTokenizer.from_pretrained(self.model_id)
        tokenizer.padding_side = "left"
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        
        model = AutoModelForCausalLM.from_pretrained(
            self.model_id,
            quantization_config=bnb_config,
            device_map="auto",
        )
        model.eval()
        
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ\n")
        return tokenizer, model
    
    def _format_prompt(self, ex):
        """í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        text = f"ë¬¸ì œ: {ex['question']}\n"
        for choice in ["A", "B", "C", "D"]:
            text += f"{choice}. {ex[choice]}\n"
        text += "ì •ë‹µ:"
        return text
    
    def _get_answer_idx(self, ex):
        """ì •ë‹µ ì¸ë±ìŠ¤"""
        ans = str(ex.get("answer", "")).strip().upper()
        if ans in self.answer_map:
            return self.answer_map[ans]
        elif ans.isdigit() and 1 <= int(ans) <= 4:
            return int(ans) - 1
        return None
    
    def _predict(self, inputs):
        """ì˜ˆì¸¡"""
        with torch.no_grad():
            logits = self.model(**inputs).logits[:, -1, :]
        
        choice_ids = [
            self.tokenizer.encode(ch, add_special_tokens=False)[0]
            for ch in ["A", "B", "C", "D"]
        ]
        
        preds = torch.argmax(logits[:, choice_ids], dim=-1)
        return preds.cpu().tolist()
    
    def evaluate(self):
        """í‰ê°€ ì‹¤í–‰"""
        results = []
        total_correct, total_count = 0, 0
        start_time = datetime.now()
        
        print("ğŸš€ í‰ê°€ ì‹œì‘...\n")
        
        for subset in tqdm(self.subsets, desc="ğŸ“Š ì§„í–‰"):
            try:
                dataset = load_dataset("HAERAE-HUB/KMMLU", subset)
                
                if "test" not in dataset:
                    continue
                
                test_data = list(dataset["test"])
                correct, count = 0, 0
                
                # ë°°ì¹˜ ì²˜ë¦¬
                for i in range(0, len(test_data), self.batch_size):
                    batch = test_data[i:i + self.batch_size]
                    prompts = [self._format_prompt(ex) for ex in batch]
                    
                    inputs = self.tokenizer(
                        prompts,
                        return_tensors="pt",
                        padding=True,
                        truncation=True,
                        max_length=2048,
                    ).to(self.model.device)
                    
                    predictions = self._predict(inputs)
                    
                    for ex, pred in zip(batch, predictions):
                        gt = self._get_answer_idx(ex)
                        if gt is not None:
                            count += 1
                            if pred == gt:
                                correct += 1
                
                # ê²°ê³¼ ì €ì¥
                accuracy = correct / count if count > 0 else 0
                category = self.categories.get(subset, "Other")
                
                results.append({
                    "Subset": subset,
                    "Category": category,
                    "Correct": correct,
                    "Total": count,
                    "Accuracy": accuracy,
                })
                
                total_correct += correct
                total_count += count
                
            except Exception as e:
                print(f"âŒ {subset} ì‹¤íŒ¨: {e}")
                continue
        
        # ê²°ê³¼ ì €ì¥
        end_time = datetime.now()
        elapsed = end_time - start_time
        
        self._save_all(results, total_correct, total_count, elapsed)
        
        print(f"\n{'='*60}")
        print(f"âœ… ì™„ë£Œ!")
        print(f"â±ï¸  ì‹œê°„: {elapsed}")
        print(f"ğŸ“Š ì •í™•ë„: {total_correct/total_count:.4f} ({total_correct}/{total_count})")
        print(f"{'='*60}\n")
    
    def _save_all(self, results, correct, total, elapsed):
        """ê²°ê³¼ ì €ì¥ (CSV + JSON + XLSX)"""
        df = pd.DataFrame(results)
        overall_acc = correct / total if total > 0 else 0
        cat_acc = df.groupby("Category")["Accuracy"].mean()
        
        # 1. CSV
        csv_file = f"{self.output_prefix}.csv"
        df.to_csv(csv_file, index=False, encoding="utf-8-sig")
        print(f"âœ… CSV: {csv_file}")
        
        # 2. JSON
        json_data = {
            "model_id": self.model_id,
            "evaluation_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "time_elapsed": str(elapsed),
            "time_elapsed_seconds": round(elapsed.total_seconds(), 2),
            "experiment_config": {
                "seed": self.seed,
                "batch_size": self.batch_size,
                "num_shots": 0,
                "prompting_strategy": "zero_shot",
            },
            "summary": {
                "overall_accuracy": round(overall_acc, 4),
                "correct_answers": correct,
                "total_questions": total,
                "category_accuracy": {k: round(v, 4) for k, v in cat_acc.to_dict().items()},
            },
            "subset_scores": [
                {
                    "subset": row["Subset"],
                    "category": row["Category"],
                    "accuracy": round(row["Accuracy"], 4),
                    "correct": row["Correct"],
                    "total": row["Total"],
                }
                for _, row in df.iterrows()
            ],
        }
        
        json_file = f"{self.output_prefix}.json"
        with open(json_file, "w", encoding="utf-8") as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… JSON: {json_file}")
        
        # 3. XLSX
        self._save_excel(df, overall_acc, cat_acc)
    
    def _save_excel(self, df, overall_acc, cat_acc):
        """XLSX ì €ì¥"""
        xlsx_file = f"{self.output_prefix}_comparison.xlsx"
        wb = openpyxl.Workbook()
        wb.remove(wb.active)
        
        # ìŠ¤íƒ€ì¼
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF")
        border = Border(
            left=Side(style='thin'), right=Side(style='thin'),
            top=Side(style='thin'), bottom=Side(style='thin')
        )
        
        # ì‹œíŠ¸ 1: ìƒì„¸
        ws1 = wb.create_sheet("4ê°€ì§€ë¶„ë¥˜ìƒì„¸")
        ws1.append(["ë¶„ì•¼", "ê³¼ëª©", "TEST", "Accuracy"])
        for _, row in df.iterrows():
            ws1.append([row["Category"], row["Subset"], row["Total"], round(row["Accuracy"], 4)])
        
        for cell in ws1[1]:
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal="center")
            cell.border = border
        
        for row in ws1.iter_rows(min_row=2, max_row=ws1.max_row):
            for cell in row:
                cell.border = border
                if cell.column == 4:
                    cell.number_format = '0.0000'
        
        ws1.column_dimensions['A'].width = 20
        ws1.column_dimensions['B'].width = 40
        ws1.column_dimensions['C'].width = 12
        ws1.column_dimensions['D'].width = 12
        
        # ì‹œíŠ¸ 2: ë¶„ì•¼ë³„
        ws2 = wb.create_sheet("ë¶„ì•¼ë³„_ìš”ì•½")
        ws2.append(["ë¶„ì•¼", "ê³¼ëª© ìˆ˜", "í‰ê·  ì •í™•ë„"])
        cat_count = df.groupby("Category").size()
        for cat in ["STEM", "HUMSS", "Applied Science", "Other"]:
            if cat in cat_acc:
                ws2.append([cat, cat_count[cat], round(cat_acc[cat], 4)])
        
        for cell in ws2[1]:
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal="center")
            cell.border = border
        
        for row in ws2.iter_rows(min_row=2, max_row=ws2.max_row):
            for cell in row:
                cell.border = border
                if cell.column == 3:
                    cell.number_format = '0.0000'
        
        # ì‹œíŠ¸ 3: í†µê³„
        ws3 = wb.create_sheet("ì „ì²´_í†µê³„")
        ws3.append(["í•­ëª©", "ê°’"])
        stats = [
            ["ëª¨ë¸", self.model_id],
            ["í‰ê°€ ë°©ë²•", "Zero-shot"],
            ["ì „ì²´ ì •í™•ë„", round(overall_acc, 4)],
            ["ê³¼ëª© ìˆ˜", len(df)],
            ["ì´ ë¬¸ì œ", df["Total"].sum()],
            ["ì •ë‹µ ìˆ˜", df["Correct"].sum()],
        ]
        for item, value in stats:
            ws3.append([item, value])
        
        for cell in ws3[1]:
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal="center")
            cell.border = border
        
        for row in ws3.iter_rows(min_row=2, max_row=ws3.max_row):
            for cell in row:
                cell.border = border
        
        wb.save(xlsx_file)
        print(f"âœ… XLSX: {xlsx_file} (3ì‹œíŠ¸)")
    
    def _get_subsets(self):
        """KMMLU 45ê°œ ê³¼ëª©"""
        return [
            "Accounting", "Agricultural-Sciences", "Aviation-Engineering-and-Maintenance",
            "Biology", "Chemical-Engineering", "Chemistry", "Civil-Engineering",
            "Computer-Science", "Construction", "Criminal-Law", "Ecology", "Economics",
            "Education", "Electrical-Engineering", "Electronics-Engineering",
            "Energy-Management", "Environmental-Science", "Fashion", "Food-Processing",
            "Gas-Technology-and-Engineering", "Geomatics", "Health", "Industrial-Engineer",
            "Information-Technology", "Interior-Architecture-and-Design", "Law",
            "Machine-Design-and-Manufacturing", "Management", "Maritime-Engineering",
            "Marketing", "Materials-Engineering", "Mechanical-Engineering",
            "Nondestructive-Testing", "Patent", "Political-Science-and-Sociology",
            "Psychology", "Public-Safety", "Railway-and-Automotive-Engineering",
            "Real-Estate", "Refrigerating-Machinery", "Social-Welfare", "Taxation",
            "Telecommunications-and-Wireless-Technology", "Korean-History", "Math",
        ]
    
    def _get_categories(self):
        """ë¶„ì•¼ ë§¤í•‘"""
        cats = {
            "STEM": [
                "Biology", "Chemical-Engineering", "Chemistry", "Civil-Engineering",
                "Computer-Science", "Ecology", "Electrical-Engineering",
                "Information-Technology", "Materials-Engineering",
                "Mechanical-Engineering", "Math",
            ],
            "HUMSS": [
                "Accounting", "Criminal-Law", "Economics", "Education", "Law",
                "Management", "Political-Science-and-Sociology", "Psychology",
                "Social-Welfare", "Taxation", "Korean-History",
            ],
            "Applied Science": [
                "Aviation-Engineering-and-Maintenance", "Electronics-Engineering",
                "Energy-Management", "Environmental-Science",
                "Gas-Technology-and-Engineering", "Geomatics", "Industrial-Engineer",
                "Machine-Design-and-Manufacturing", "Maritime-Engineering",
                "Nondestructive-Testing", "Railway-and-Automotive-Engineering",
                "Telecommunications-and-Wireless-Technology",
            ],
            "Other": [
                "Agricultural-Sciences", "Construction", "Fashion", "Food-Processing",
                "Health", "Interior-Architecture-and-Design", "Marketing", "Patent",
                "Public-Safety", "Real-Estate", "Refrigerating-Machinery",
            ],
        }
        return {s: cat for cat, subs in cats.items() for s in subs}


def main():
    parser = argparse.ArgumentParser(description="KMMLU A.X Zero-shot í‰ê°€")
    parser.add_argument("--model_id", type=str, default="skt/A.X-4.0-Light")
    parser.add_argument("--batch_size", type=int, default=2)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--output_prefix", type=str, default="kmmlu_ax_zeroshot")
    
    args = parser.parse_args()
    
    evaluator = KMMLUEvaluator(
        model_id=args.model_id,
        batch_size=args.batch_size,
        seed=args.seed,
        output_prefix=args.output_prefix,
    )
    
    evaluator.evaluate()


if __name__ == "__main__":
    main()
